{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# This is a Kaggle competition to predict the probability of 0 or 1 of Tabular Playground series data\n",
    "## I will be comparing which model to use: XGB, Random Forest or Neural Networks\n",
    "\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "from keras import initializers\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Read a training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:/Users/taihs/OneDrive/Documents/tps competition/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Find the number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      300000 non-null  int64  \n",
      " 1   cat0    300000 non-null  object \n",
      " 2   cat1    300000 non-null  object \n",
      " 3   cat2    300000 non-null  object \n",
      " 4   cat3    300000 non-null  object \n",
      " 5   cat4    300000 non-null  object \n",
      " 6   cat5    300000 non-null  object \n",
      " 7   cat6    300000 non-null  object \n",
      " 8   cat7    300000 non-null  object \n",
      " 9   cat8    300000 non-null  object \n",
      " 10  cat9    300000 non-null  object \n",
      " 11  cat10   300000 non-null  object \n",
      " 12  cat11   300000 non-null  object \n",
      " 13  cat12   300000 non-null  object \n",
      " 14  cat13   300000 non-null  object \n",
      " 15  cat14   300000 non-null  object \n",
      " 16  cat15   300000 non-null  object \n",
      " 17  cat16   300000 non-null  object \n",
      " 18  cat17   300000 non-null  object \n",
      " 19  cat18   300000 non-null  object \n",
      " 20  cont0   300000 non-null  float64\n",
      " 21  cont1   300000 non-null  float64\n",
      " 22  cont2   300000 non-null  float64\n",
      " 23  cont3   300000 non-null  float64\n",
      " 24  cont4   300000 non-null  float64\n",
      " 25  cont5   300000 non-null  float64\n",
      " 26  cont6   300000 non-null  float64\n",
      " 27  cont7   300000 non-null  float64\n",
      " 28  cont8   300000 non-null  float64\n",
      " 29  cont9   300000 non-null  float64\n",
      " 30  cont10  300000 non-null  float64\n",
      " 31  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(2), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont2     cont3  \\\n",
       "0   0    A    I    A    B    B   BI    A    S    Q  ...  0.759439  0.795549   \n",
       "1   1    A    I    A    A    E   BI    K    W   AD  ...  0.386385  0.541366   \n",
       "2   2    A    K    A    A    E   BI    A    E   BM  ...  0.343255  0.616352   \n",
       "3   3    A    K    A    C    E   BI    A    Y   AD  ...  0.831147  0.807807   \n",
       "4   4    A    I    G    B    E   BI    C    G    Q  ...  0.338818  0.277308   \n",
       "\n",
       "      cont4     cont5     cont6     cont7     cont8     cont9    cont10 target  \n",
       "0  0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915      0  \n",
       "1  0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729      0  \n",
       "2  0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452      0  \n",
       "3  0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242      0  \n",
       "4  0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "cont5     0.215184\n",
       "cont6     0.189832\n",
       "cont8     0.183726\n",
       "cont1     0.164655\n",
       "cont2     0.140459\n",
       "cont9     0.059242\n",
       "id       -0.001407\n",
       "cont0    -0.015172\n",
       "cont7    -0.040646\n",
       "cont10   -0.047077\n",
       "cont4    -0.075585\n",
       "cont3    -0.148316\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co = df1.corr()\n",
    "co['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>148852</td>\n",
       "      <td>74673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>71687</td>\n",
       "      <td>4788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target       0      1\n",
       "cat0                 \n",
       "A       148852  74673\n",
       "B        71687   4788"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df1['cat0'],df1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cat0', ylabel='target'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x=df1['cat0'],y=df1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cat0', ylabel='count'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df1['cat0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cat1', ylabel='target'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=df1['cat1'],y=df1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cat9', ylabel='Count'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=df1['cat9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df1.select_dtypes(include='object').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cat0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148852</td>\n",
       "      <td>71687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74673</td>\n",
       "      <td>4788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cat0         A      B\n",
       "target               \n",
       "0       148852  71687\n",
       "1        74673   4788"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df1['target'],df1['cat0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Column              Hypothesis\n",
      "0    cat0  Reject Null Hypothesis\n",
      "1    cat1  Reject Null Hypothesis\n",
      "2    cat2  Reject Null Hypothesis\n",
      "3    cat3  Reject Null Hypothesis\n",
      "4    cat4  Reject Null Hypothesis\n",
      "5    cat5  Reject Null Hypothesis\n",
      "6    cat6  Reject Null Hypothesis\n",
      "7    cat7  Reject Null Hypothesis\n",
      "8    cat8  Reject Null Hypothesis\n",
      "9    cat9  Reject Null Hypothesis\n",
      "10  cat10  Reject Null Hypothesis\n",
      "11  cat11  Reject Null Hypothesis\n",
      "12  cat12  Reject Null Hypothesis\n",
      "13  cat13  Reject Null Hypothesis\n",
      "14  cat14  Reject Null Hypothesis\n",
      "15  cat15  Reject Null Hypothesis\n",
      "16  cat16  Reject Null Hypothesis\n",
      "17  cat17  Reject Null Hypothesis\n",
      "18  cat18  Reject Null Hypothesis\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2_check = []\n",
    "for i in cat:\n",
    "    if chi2_contingency(pd.crosstab(df1['target'], df1[i]))[1] < 0.05:\n",
    "        chi2_check.append('Reject Null Hypothesis')\n",
    "    else:\n",
    "        chi2_check.append('Fail to Reject Null Hypothesis')\n",
    "res = pd.DataFrame(data = [cat, chi2_check] \n",
    "             ).T \n",
    "res.columns = ['Column', 'Hypothesis']\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lst = res['Column'].tolist()\n",
    "le = LabelEncoder()\n",
    "df3 = pd.DataFrame()\n",
    "for i in lst:\n",
    "    icat = le.fit_transform(df1[i])\n",
    "    df2 = pd.DataFrame({i:icat})\n",
    "    df3 = pd.concat([df3,df2],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  \\\n",
       "0          0     8     0     1     1    33     0    44    54     0    258   \n",
       "1          0     8     0     0     4    33     8    48     3     5    162   \n",
       "2          0    10     0     0     4    33     0    30    38     9     69   \n",
       "3          0    10     0     2     4    33     0    50     3     5    241   \n",
       "4          0     8     6     1     4    33     2    32    54     0     75   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   \n",
       "299995     0    13     5     0     4    45     0    19    48     0    159   \n",
       "299996     0    10     0     0     6    33     0    36     4     4    163   \n",
       "299997     0     6    12     0     7    33     2    37    43     0    156   \n",
       "299998     1     7     0     3     1    33     0     1    23     0     25   \n",
       "299999     0     5     2     0     4    33     2    22    55     0    256   \n",
       "\n",
       "        cat11  cat12  cat13  cat14  cat15  cat16  cat17  cat18  \n",
       "0           0      0      0      0      1      3      3      1  \n",
       "1           0      1      0      1      3      1      3      1  \n",
       "2           0      1      0      0      1      3      3      1  \n",
       "3           0      0      0      0      1      3      3      1  \n",
       "4           0      0      0      1      1      1      3      1  \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "299995      0      0      0      1      3      1      3      1  \n",
       "299996      0      1      0      1      1      3      3      1  \n",
       "299997      1      0      0      1      3      1      3      3  \n",
       "299998      0      0      0      0      1      0      3      0  \n",
       "299999      0      0      0      0      1      3      3      1  \n",
       "\n",
       "[300000 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 30)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([df3,df1[['cont0','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10']]],axis=1)\n",
    "#X = pd.concat([df3,df1[['cont1','cont2','cont5','cont6','cont8','cont9']]],axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(['cont0','cont9','cat3','cont10','cont7','cont8','cat5','cat7','cont3'],axis=1,inplace=True)\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   cat0    300000 non-null  int32\n",
      " 1   cat1    300000 non-null  int32\n",
      " 2   cat2    300000 non-null  int32\n",
      " 3   cat3    300000 non-null  int32\n",
      " 4   cat4    300000 non-null  int32\n",
      " 5   cat5    300000 non-null  int32\n",
      " 6   cat6    300000 non-null  int32\n",
      " 7   cat7    300000 non-null  int32\n",
      " 8   cat8    300000 non-null  int32\n",
      " 9   cat9    300000 non-null  int32\n",
      " 10  cat10   300000 non-null  int32\n",
      " 11  cat11   300000 non-null  int32\n",
      " 12  cat12   300000 non-null  int32\n",
      " 13  cat13   300000 non-null  int32\n",
      " 14  cat14   300000 non-null  int32\n",
      " 15  cat15   300000 non-null  int32\n",
      " 16  cat16   300000 non-null  int32\n",
      " 17  cat17   300000 non-null  int32\n",
      " 18  cat18   300000 non-null  int32\n",
      " 19  cont0   300000 non-null  int32\n",
      " 20  cont1   300000 non-null  int32\n",
      " 21  cont2   300000 non-null  int32\n",
      " 22  cont3   300000 non-null  int32\n",
      " 23  cont4   300000 non-null  int32\n",
      " 24  cont5   300000 non-null  int32\n",
      " 25  cont6   300000 non-null  int32\n",
      " 26  cont7   300000 non-null  int32\n",
      " 27  cont8   300000 non-null  int32\n",
      " 28  cont9   300000 non-null  int32\n",
      " 29  cont10  300000 non-null  int32\n",
      "dtypes: int32(30)\n",
      "memory usage: 34.3 MB\n"
     ]
    }
   ],
   "source": [
    "X=X.astype('int')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the features and split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "#X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df1['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc = preprocessing.StandardScaler()\n",
    "X_train= Sc.fit(X_train).transform(X_train)\n",
    "X_test= Sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taihs\\anaconda3\\envs\\new_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:56:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=200)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06706327, 0.01498194, 0.01170831, 0.00534046, 0.02624277,\n",
       "       0.01102255, 0.00766307, 0.00865909, 0.00895882, 0.00728115,\n",
       "       0.00829969, 0.03372672, 0.01341711, 0.05380396, 0.0325352 ,\n",
       "       0.06184799, 0.5215331 , 0.01997108, 0.06541748, 0.        ,\n",
       "       0.00357563, 0.00081129, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00248556, 0.0136539 , 0.        , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.843\n",
      "roc-auc is 0.882\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_xgb = xgb.predict(X_test)\n",
    "y_pred_prob_xgb = xgb.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_xgb)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_xgb[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.830\n",
      "roc-auc is 0.860\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99770972e-02, 7.00512276e-02, 6.37486688e-02, 3.89299671e-02,\n",
       "       5.57498776e-02, 2.06770367e-02, 3.91405452e-02, 1.00866290e-01,\n",
       "       8.93126621e-02, 3.30580807e-02, 9.17392940e-02, 2.29304332e-02,\n",
       "       8.34036641e-03, 7.72252991e-03, 3.48935006e-02, 8.22642392e-02,\n",
       "       1.33183385e-01, 2.87439834e-02, 5.72317904e-02, 0.00000000e+00,\n",
       "       4.80266574e-05, 3.08989410e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.51037462e-04, 1.15551804e-03,\n",
       "       2.24381089e-05, 3.11061137e-05])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>AX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735690</td>\n",
       "      <td>0.578366</td>\n",
       "      <td>0.723154</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.356227</td>\n",
       "      <td>0.551249</td>\n",
       "      <td>0.655693</td>\n",
       "      <td>0.598331</td>\n",
       "      <td>0.359987</td>\n",
       "      <td>0.947489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>AB</td>\n",
       "      <td>I</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313703</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.600169</td>\n",
       "      <td>0.795224</td>\n",
       "      <td>0.248987</td>\n",
       "      <td>0.654614</td>\n",
       "      <td>0.347944</td>\n",
       "      <td>0.565520</td>\n",
       "      <td>0.388580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>AB</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448201</td>\n",
       "      <td>0.424876</td>\n",
       "      <td>0.344729</td>\n",
       "      <td>0.242073</td>\n",
       "      <td>0.270632</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>0.341238</td>\n",
       "      <td>0.252289</td>\n",
       "      <td>0.411592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>L</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>AX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666092</td>\n",
       "      <td>0.598943</td>\n",
       "      <td>0.561971</td>\n",
       "      <td>0.806347</td>\n",
       "      <td>0.735983</td>\n",
       "      <td>0.538724</td>\n",
       "      <td>0.381566</td>\n",
       "      <td>0.481660</td>\n",
       "      <td>0.348514</td>\n",
       "      <td>0.325723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772229</td>\n",
       "      <td>0.479572</td>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.252454</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.178920</td>\n",
       "      <td>0.763479</td>\n",
       "      <td>0.562491</td>\n",
       "      <td>0.466261</td>\n",
       "      <td>0.585781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont1     cont2  \\\n",
       "0   5    A    F    A    A    F   BI    A   AH   AX  ...  0.735690  0.578366   \n",
       "1   6    A    H    C    A    E   AB    I    F    N  ...  0.313703  0.928885   \n",
       "2   8    A    N    C    A    F   AB    A   AH   BC  ...  0.448201  0.424876   \n",
       "3   9    B    L    C    A    F   BI    A    E   AX  ...  0.666092  0.598943   \n",
       "4  11    A    F    A    B    F   BI    A   AH    I  ...  0.772229  0.479572   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7     cont8     cont9  \\\n",
       "0  0.723154  0.228037  0.356227  0.551249  0.655693  0.598331  0.359987   \n",
       "1  0.516602  0.600169  0.795224  0.248987  0.654614  0.347944  0.565520   \n",
       "2  0.344729  0.242073  0.270632  0.746740  0.335590  0.341238  0.252289   \n",
       "3  0.561971  0.806347  0.735983  0.538724  0.381566  0.481660  0.348514   \n",
       "4  0.767745  0.252454  0.354810  0.178920  0.763479  0.562491  0.466261   \n",
       "\n",
       "     cont10  \n",
       "0  0.947489  \n",
       "1  0.388580  \n",
       "2  0.411592  \n",
       "3  0.325723  \n",
       "4  0.585781  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('C:/Users/taihs/OneDrive/Documents/tps competition/test.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "lst = res['Column'].tolist()\n",
    "df3 = pd.DataFrame()\n",
    "for i in lst:\n",
    "    icat = le.fit_transform(df1[i])\n",
    "    df2 = pd.DataFrame({i:icat})\n",
    "    df3 = pd.concat([df3,df2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  \\\n",
       "0          0     5     0     0     5    33     0     8    23     0    249   \n",
       "1          0     7     2     0     4     2     7    31    51     0    269   \n",
       "2          0    13     2     0     5     2     0     8    28     0    121   \n",
       "3          1    11     2     0     5    33     0    30    23     0    162   \n",
       "4          0     5     0     1     5    33     0     8    46     0    173   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   \n",
       "199995     0    13     0     3     5    33     0     6    23     0     75   \n",
       "199996     1     8     0     1     4    33     0    19    55     4    180   \n",
       "199997     0    11     3     0     7    33     0    14    47     0    171   \n",
       "199998     0    10     0     2     5    33     0    43    38     0    162   \n",
       "199999     0    10     0     0     4    33     2    15    38     7     69   \n",
       "\n",
       "        cat11  cat12  cat13  cat14  cat15  cat16  cat17  cat18  \n",
       "0           0      0      0      0      1      3      3      1  \n",
       "1           0      0      0      1      3      1      3      1  \n",
       "2           0      0      0      1      1      3      3      1  \n",
       "3           0      0      0      0      1      3      1      1  \n",
       "4           0      0      0      0      3      3      3      1  \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "199995      0      0      0      1      3      1      2      1  \n",
       "199996      0      0      0      1      1      3      3      1  \n",
       "199997      0      0      0      1      3      1      3      1  \n",
       "199998      0      0      0      0      1      3      3      1  \n",
       "199999      0      1      0      0      1      1      1      1  \n",
       "\n",
       "[200000 rows x 19 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735690</td>\n",
       "      <td>0.578366</td>\n",
       "      <td>0.723154</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.356227</td>\n",
       "      <td>0.551249</td>\n",
       "      <td>0.655693</td>\n",
       "      <td>0.598331</td>\n",
       "      <td>0.359987</td>\n",
       "      <td>0.947489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313703</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.600169</td>\n",
       "      <td>0.795224</td>\n",
       "      <td>0.248987</td>\n",
       "      <td>0.654614</td>\n",
       "      <td>0.347944</td>\n",
       "      <td>0.565520</td>\n",
       "      <td>0.388580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448201</td>\n",
       "      <td>0.424876</td>\n",
       "      <td>0.344729</td>\n",
       "      <td>0.242073</td>\n",
       "      <td>0.270632</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>0.341238</td>\n",
       "      <td>0.252289</td>\n",
       "      <td>0.411592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666092</td>\n",
       "      <td>0.598943</td>\n",
       "      <td>0.561971</td>\n",
       "      <td>0.806347</td>\n",
       "      <td>0.735983</td>\n",
       "      <td>0.538724</td>\n",
       "      <td>0.381566</td>\n",
       "      <td>0.481660</td>\n",
       "      <td>0.348514</td>\n",
       "      <td>0.325723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772229</td>\n",
       "      <td>0.479572</td>\n",
       "      <td>0.767745</td>\n",
       "      <td>0.252454</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.178920</td>\n",
       "      <td>0.763479</td>\n",
       "      <td>0.562491</td>\n",
       "      <td>0.466261</td>\n",
       "      <td>0.585781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361426</td>\n",
       "      <td>0.351946</td>\n",
       "      <td>0.327670</td>\n",
       "      <td>0.205547</td>\n",
       "      <td>0.679195</td>\n",
       "      <td>0.485967</td>\n",
       "      <td>0.319130</td>\n",
       "      <td>0.520681</td>\n",
       "      <td>0.519545</td>\n",
       "      <td>0.427119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551106</td>\n",
       "      <td>0.628843</td>\n",
       "      <td>0.677765</td>\n",
       "      <td>0.624935</td>\n",
       "      <td>0.555306</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.700829</td>\n",
       "      <td>0.531728</td>\n",
       "      <td>0.528427</td>\n",
       "      <td>0.922645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812384</td>\n",
       "      <td>0.803348</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>0.665624</td>\n",
       "      <td>0.488447</td>\n",
       "      <td>0.853213</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.811941</td>\n",
       "      <td>0.537106</td>\n",
       "      <td>0.531758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811282</td>\n",
       "      <td>0.820635</td>\n",
       "      <td>0.561449</td>\n",
       "      <td>0.797434</td>\n",
       "      <td>0.555089</td>\n",
       "      <td>0.746532</td>\n",
       "      <td>0.369986</td>\n",
       "      <td>0.438712</td>\n",
       "      <td>0.715524</td>\n",
       "      <td>0.381978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336168</td>\n",
       "      <td>0.270483</td>\n",
       "      <td>0.581868</td>\n",
       "      <td>0.218993</td>\n",
       "      <td>0.553284</td>\n",
       "      <td>0.565213</td>\n",
       "      <td>0.378355</td>\n",
       "      <td>0.547927</td>\n",
       "      <td>0.273595</td>\n",
       "      <td>0.448016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...  \\\n",
       "0          0     5     0     0     5    33     0     8    23     0  ...   \n",
       "1          0     7     2     0     4     2     7    31    51     0  ...   \n",
       "2          0    13     2     0     5     2     0     8    28     0  ...   \n",
       "3          1    11     2     0     5    33     0    30    23     0  ...   \n",
       "4          0     5     0     1     5    33     0     8    46     0  ...   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "199995     0    13     0     3     5    33     0     6    23     0  ...   \n",
       "199996     1     8     0     1     4    33     0    19    55     4  ...   \n",
       "199997     0    11     3     0     7    33     0    14    47     0  ...   \n",
       "199998     0    10     0     2     5    33     0    43    38     0  ...   \n",
       "199999     0    10     0     0     4    33     2    15    38     7  ...   \n",
       "\n",
       "           cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0       0.735690  0.578366  0.723154  0.228037  0.356227  0.551249  0.655693   \n",
       "1       0.313703  0.928885  0.516602  0.600169  0.795224  0.248987  0.654614   \n",
       "2       0.448201  0.424876  0.344729  0.242073  0.270632  0.746740  0.335590   \n",
       "3       0.666092  0.598943  0.561971  0.806347  0.735983  0.538724  0.381566   \n",
       "4       0.772229  0.479572  0.767745  0.252454  0.354810  0.178920  0.763479   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  0.361426  0.351946  0.327670  0.205547  0.679195  0.485967  0.319130   \n",
       "199996  0.551106  0.628843  0.677765  0.624935  0.555306  0.242424  0.700829   \n",
       "199997  0.812384  0.803348  0.324762  0.665624  0.488447  0.853213  0.578641   \n",
       "199998  0.811282  0.820635  0.561449  0.797434  0.555089  0.746532  0.369986   \n",
       "199999  0.336168  0.270483  0.581868  0.218993  0.553284  0.565213  0.378355   \n",
       "\n",
       "           cont8     cont9    cont10  \n",
       "0       0.598331  0.359987  0.947489  \n",
       "1       0.347944  0.565520  0.388580  \n",
       "2       0.341238  0.252289  0.411592  \n",
       "3       0.481660  0.348514  0.325723  \n",
       "4       0.562491  0.466261  0.585781  \n",
       "...          ...       ...       ...  \n",
       "199995  0.520681  0.519545  0.427119  \n",
       "199996  0.531728  0.528427  0.922645  \n",
       "199997  0.811941  0.537106  0.531758  \n",
       "199998  0.438712  0.715524  0.381978  \n",
       "199999  0.547927  0.273595  0.448016  \n",
       "\n",
       "[200000 rows x 30 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([df3,df1[['cont0','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10']]],axis=1)\n",
    "#X = pd.concat([df3,df1[['cont1','cont2','cont5','cont6','cont8','cont9']]],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(['cont0','cont9','cat3','cont10','cont7','cont8','cat5','cat7','cont3'],axis=1,inplace=True)\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   cat0    200000 non-null  int32\n",
      " 1   cat1    200000 non-null  int32\n",
      " 2   cat2    200000 non-null  int32\n",
      " 3   cat3    200000 non-null  int32\n",
      " 4   cat4    200000 non-null  int32\n",
      " 5   cat5    200000 non-null  int32\n",
      " 6   cat6    200000 non-null  int32\n",
      " 7   cat7    200000 non-null  int32\n",
      " 8   cat8    200000 non-null  int32\n",
      " 9   cat9    200000 non-null  int32\n",
      " 10  cat10   200000 non-null  int32\n",
      " 11  cat11   200000 non-null  int32\n",
      " 12  cat12   200000 non-null  int32\n",
      " 13  cat13   200000 non-null  int32\n",
      " 14  cat14   200000 non-null  int32\n",
      " 15  cat15   200000 non-null  int32\n",
      " 16  cat16   200000 non-null  int32\n",
      " 17  cat17   200000 non-null  int32\n",
      " 18  cat18   200000 non-null  int32\n",
      " 19  cont0   200000 non-null  int32\n",
      " 20  cont1   200000 non-null  int32\n",
      " 21  cont2   200000 non-null  int32\n",
      " 22  cont3   200000 non-null  int32\n",
      " 23  cont4   200000 non-null  int32\n",
      " 24  cont5   200000 non-null  int32\n",
      " 25  cont6   200000 non-null  int32\n",
      " 26  cont7   200000 non-null  int32\n",
      " 27  cont8   200000 non-null  int32\n",
      " 28  cont9   200000 non-null  int32\n",
      " 29  cont10  200000 non-null  int32\n",
      "dtypes: int32(30)\n",
      "memory usage: 22.9 MB\n"
     ]
    }
   ],
   "source": [
    "X=X.astype('int')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.84871536e-01, -1.01120305e+00, -6.36230407e-01,\n",
       "        -5.18058919e-01,  1.29465996e-01,  2.65387358e-01,\n",
       "        -5.97737446e-01, -1.11838839e+00, -5.52753344e-01,\n",
       "        -5.86271243e-01,  1.47795544e+00, -3.98550559e-01,\n",
       "        -4.10999678e-01, -1.59865185e-01, -9.35975115e-01,\n",
       "        -5.62749702e-01,  6.59929099e-01,  4.28600036e-01,\n",
       "        -3.85341368e-01, -2.23607357e-03, -6.32468182e-03,\n",
       "        -7.74619908e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.88216841e-02,\n",
       "        -6.52923950e-02, -7.07124460e-03, -1.11810387e-02],\n",
       "       [-5.84871536e-01, -3.62062827e-01, -1.52758874e-01,\n",
       "        -5.18058919e-01, -5.33136983e-01, -2.17765193e+00,\n",
       "         2.71391909e+00,  5.37757899e-01,  9.20319820e-01,\n",
       "        -5.86271243e-01,  1.75172996e+00, -3.98550559e-01,\n",
       "        -4.10999678e-01, -1.59865185e-01,  1.06840447e+00,\n",
       "         1.56988773e+00, -1.49372835e+00,  4.28600036e-01,\n",
       "        -3.85341368e-01, -2.23607357e-03, -6.32468182e-03,\n",
       "        -7.74619908e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.88216841e-02,\n",
       "        -6.52923950e-02, -7.07124460e-03, -1.11810387e-02],\n",
       "       [-5.84871536e-01,  1.58535784e+00, -1.52758874e-01,\n",
       "        -5.18058919e-01,  1.29465996e-01, -2.17765193e+00,\n",
       "        -5.97737446e-01, -1.11838839e+00, -2.89704564e-01,\n",
       "        -5.86271243e-01, -2.74201469e-01, -3.98550559e-01,\n",
       "        -4.10999678e-01, -1.59865185e-01,  1.06840447e+00,\n",
       "        -5.62749702e-01,  6.59929099e-01,  4.28600036e-01,\n",
       "        -3.85341368e-01, -2.23607357e-03, -6.32468182e-03,\n",
       "        -7.74619908e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.88216841e-02,\n",
       "        -6.52923950e-02, -7.07124460e-03, -1.11810387e-02],\n",
       "       [ 1.70977717e+00,  9.36217616e-01, -1.52758874e-01,\n",
       "        -5.18058919e-01,  1.29465996e-01,  2.65387358e-01,\n",
       "        -5.97737446e-01,  4.65751539e-01, -5.52753344e-01,\n",
       "        -5.86271243e-01,  2.87036292e-01, -3.98550559e-01,\n",
       "        -4.10999678e-01, -1.59865185e-01, -9.35975115e-01,\n",
       "        -5.62749702e-01,  6.59929099e-01, -2.74786210e+00,\n",
       "        -3.85341368e-01, -2.23607357e-03, -6.32468182e-03,\n",
       "        -7.74619908e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.88216841e-02,\n",
       "        -6.52923950e-02, -7.07124460e-03, -1.11810387e-02],\n",
       "       [-5.84871536e-01, -1.01120305e+00, -6.36230407e-01,\n",
       "         3.14271210e-01,  1.29465996e-01,  2.65387358e-01,\n",
       "        -5.97737446e-01, -1.11838839e+00,  6.57271041e-01,\n",
       "        -5.86271243e-01,  4.37612276e-01, -3.98550559e-01,\n",
       "        -4.10999678e-01, -1.59865185e-01, -9.35975115e-01,\n",
       "         1.56988773e+00,  6.59929099e-01,  4.28600036e-01,\n",
       "        -3.85341368e-01, -2.23607357e-03, -6.32468182e-03,\n",
       "        -7.74619908e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.88216841e-02,\n",
       "        -6.52923950e-02, -7.07124460e-03, -1.11810387e-02]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_class_rf = rf_model.predict(X)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X)\n",
    "\n",
    "y_pred_class_xgb = xgb.predict(X)\n",
    "y_pred_prob_xgb = xgb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00081129, 0.00248556, 0.00357563,\n",
       "       0.00534046, 0.00728115, 0.00766307, 0.00829969, 0.00865909,\n",
       "       0.00895882, 0.01102255, 0.01170831, 0.01341711, 0.0136539 ,\n",
       "       0.01498194, 0.01997108, 0.02624277, 0.0325352 , 0.03372672,\n",
       "       0.05380396, 0.06184799, 0.06541748, 0.06706327, 0.5215331 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.feature_importances_\n",
    "np.sort(xgb.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1447803 , 0.30961773, 0.04213469, ..., 0.69286907, 0.03106131,\n",
       "       0.6059582 ], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred_prob_rf[:,1]\n",
    "y_pred_prob_xgb[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.871420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.014474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.692869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0.031061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.605958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target\n",
       "199995  0.871420\n",
       "199996  0.014474\n",
       "199997  0.692869\n",
       "199998  0.031061\n",
       "199999  0.605958"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final = pd.DataFrame({'target':y_pred_prob_rf[:,1]})\n",
    "final = pd.DataFrame({'target':y_pred_prob_xgb[:,1]})\n",
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499983</td>\n",
       "      <td>0.871420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499984</td>\n",
       "      <td>0.014474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499987</td>\n",
       "      <td>0.692869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499994</td>\n",
       "      <td>0.031061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499998</td>\n",
       "      <td>0.605958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target\n",
       "199995  499983  0.871420\n",
       "199996  499984  0.014474\n",
       "199997  499987  0.692869\n",
       "199998  499994  0.031061\n",
       "199999  499998  0.605958"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1 = pd.concat([df1['id'],final],axis=1)\n",
    "final1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Neural Network model with one hidden layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (30,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.4596 - accuracy: 0.7929 - val_loss: 0.4102 - val_accuracy: 0.8256\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.4018 - accuracy: 0.8284 - val_loss: 0.3997 - val_accuracy: 0.8269\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3969 - accuracy: 0.8287 - val_loss: 0.3976 - val_accuracy: 0.8281\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3955 - accuracy: 0.8291 - val_loss: 0.3967 - val_accuracy: 0.8282\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3947 - accuracy: 0.8291 - val_loss: 0.3961 - val_accuracy: 0.8285\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3942 - accuracy: 0.8293 - val_loss: 0.3957 - val_accuracy: 0.8285\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3939 - accuracy: 0.8292 - val_loss: 0.3954 - val_accuracy: 0.8285\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3936 - accuracy: 0.8294 - val_loss: 0.3951 - val_accuracy: 0.8285\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3933 - accuracy: 0.8294 - val_loss: 0.3949 - val_accuracy: 0.8290\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3931 - accuracy: 0.8294 - val_loss: 0.3947 - val_accuracy: 0.8290\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3929 - accuracy: 0.8296 - val_loss: 0.3945 - val_accuracy: 0.82919 - ac\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3926 - accuracy: 0.8298 - val_loss: 0.3943 - val_accuracy: 0.8292\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3924 - accuracy: 0.8299 - val_loss: 0.3941 - val_accuracy: 0.8291\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 10s 1ms/step - loss: 0.3922 - accuracy: 0.8300 - val_loss: 0.3939 - val_accuracy: 0.8292\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3920 - accuracy: 0.8301 - val_loss: 0.3937 - val_accuracy: 0.8293\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3918 - accuracy: 0.8301 - val_loss: 0.3935 - val_accuracy: 0.8299\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3916 - accuracy: 0.8303 - val_loss: 0.3933 - val_accuracy: 0.8298\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3914 - accuracy: 0.8305 - val_loss: 0.3931 - val_accuracy: 0.8299\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3912 - accuracy: 0.8306 - val_loss: 0.3929 - val_accuracy: 0.8302\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3910 - accuracy: 0.8307 - val_loss: 0.3928 - val_accuracy: 0.8302\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3908 - accuracy: 0.8309 - val_loss: 0.3926 - val_accuracy: 0.8303\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3907 - accuracy: 0.8310 - val_loss: 0.3924 - val_accuracy: 0.8303\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3905 - accuracy: 0.8312 - val_loss: 0.3923 - val_accuracy: 0.8304\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3903 - accuracy: 0.8314 - val_loss: 0.3922 - val_accuracy: 0.8306\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 10s 1ms/step - loss: 0.3901 - accuracy: 0.8315 - val_loss: 0.3921 - val_accuracy: 0.8302\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3900 - accuracy: 0.8315 - val_loss: 0.3919 - val_accuracy: 0.8303\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3898 - accuracy: 0.8316 - val_loss: 0.3918 - val_accuracy: 0.8306\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3897 - accuracy: 0.8317 - val_loss: 0.3916 - val_accuracy: 0.8308\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3896 - accuracy: 0.8318 - val_loss: 0.3915 - val_accuracy: 0.8308\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3894 - accuracy: 0.8320 - val_loss: 0.3914 - val_accuracy: 0.8305\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3893 - accuracy: 0.8319 - val_loss: 0.3912 - val_accuracy: 0.8311\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3892 - accuracy: 0.8320 - val_loss: 0.3911 - val_accuracy: 0.8313\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3891 - accuracy: 0.8321 - val_loss: 0.3911 - val_accuracy: 0.8311\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3889 - accuracy: 0.8321 - val_loss: 0.3910 - val_accuracy: 0.8310\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3888 - accuracy: 0.8323 - val_loss: 0.3908 - val_accuracy: 0.8311\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3887 - accuracy: 0.8324 - val_loss: 0.3907 - val_accuracy: 0.8313\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3886 - accuracy: 0.8324 - val_loss: 0.3906 - val_accuracy: 0.8314\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3885 - accuracy: 0.8324 - val_loss: 0.3906 - val_accuracy: 0.8314\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3884 - accuracy: 0.8324 - val_loss: 0.3905 - val_accuracy: 0.8314\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 9s 1ms/step - loss: 0.3883 - accuracy: 0.8324 - val_loss: 0.3904 - val_accuracy: 0.8313\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 8s 1ms/step - loss: 0.3882 - accuracy: 0.8323 - val_loss: 0.3903 - val_accuracy: 0.8315\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 4s 505us/step - loss: 0.3882 - accuracy: 0.8326 - val_loss: 0.3902 - val_accuracy: 0.8317\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 4s 519us/step - loss: 0.3881 - accuracy: 0.8326 - val_loss: 0.3902 - val_accuracy: 0.8316\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 4s 512us/step - loss: 0.3880 - accuracy: 0.8326 - val_loss: 0.3901 - val_accuracy: 0.8314\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 4s 513us/step - loss: 0.3879 - accuracy: 0.8325 - val_loss: 0.3900 - val_accuracy: 0.8315\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 4s 518us/step - loss: 0.3878 - accuracy: 0.8328 - val_loss: 0.3899 - val_accuracy: 0.8316\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 4s 522us/step - loss: 0.3878 - accuracy: 0.8328 - val_loss: 0.3899 - val_accuracy: 0.8313\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 4s 540us/step - loss: 0.3877 - accuracy: 0.8328 - val_loss: 0.3898 - val_accuracy: 0.8315\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 4s 549us/step - loss: 0.3876 - accuracy: 0.8329 - val_loss: 0.3898 - val_accuracy: 0.8313\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 0.3875 - accuracy: 0.8329 - val_loss: 0.3899 - val_accuracy: 0.8313\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-98292c949c9b>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.831\n",
      "roc-auc is 0.860\n"
     ]
    }
   ],
   "source": [
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d106066eb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add two hidden layers to the Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (30,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(12,activation='sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 5s 662us/step - loss: 0.5806 - accuracy: 0.7330 - val_loss: 0.5639 - val_accuracy: 0.7362\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 5s 684us/step - loss: 0.5435 - accuracy: 0.7348 - val_loss: 0.5123 - val_accuracy: 0.7362\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 6s 745us/step - loss: 0.4714 - accuracy: 0.7645 - val_loss: 0.4353 - val_accuracy: 0.8162\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 5s 624us/step - loss: 0.4177 - accuracy: 0.8256 - val_loss: 0.4091 - val_accuracy: 0.8263\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 5s 628us/step - loss: 0.4043 - accuracy: 0.8284 - val_loss: 0.4036 - val_accuracy: 0.8271\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 5s 630us/step - loss: 0.4007 - accuracy: 0.8286 - val_loss: 0.4014 - val_accuracy: 0.8274\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 5s 640us/step - loss: 0.3989 - accuracy: 0.8288 - val_loss: 0.4000 - val_accuracy: 0.8280\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 5s 651us/step - loss: 0.3977 - accuracy: 0.8293 - val_loss: 0.3990 - val_accuracy: 0.8281\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 5s 622us/step - loss: 0.3969 - accuracy: 0.8296 - val_loss: 0.3983 - val_accuracy: 0.8285\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 5s 641us/step - loss: 0.3962 - accuracy: 0.8294 - val_loss: 0.3977 - val_accuracy: 0.8285\n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 5s 631us/step - loss: 0.3956 - accuracy: 0.8295 - val_loss: 0.3972 - val_accuracy: 0.8286\n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 5s 723us/step - loss: 0.3951 - accuracy: 0.8298 - val_loss: 0.3967 - val_accuracy: 0.8290\n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 6s 767us/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.3962 - val_accuracy: 0.8288\n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 5s 733us/step - loss: 0.3943 - accuracy: 0.8301 - val_loss: 0.3959 - val_accuracy: 0.8292\n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 5s 717us/step - loss: 0.3939 - accuracy: 0.8303 - val_loss: 0.3954 - val_accuracy: 0.8299\n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 6s 768us/step - loss: 0.3935 - accuracy: 0.8303 - val_loss: 0.3951 - val_accuracy: 0.8298\n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 6s 734us/step - loss: 0.3931 - accuracy: 0.8304 - val_loss: 0.3947 - val_accuracy: 0.8301\n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 5s 691us/step - loss: 0.3928 - accuracy: 0.8306 - val_loss: 0.3944 - val_accuracy: 0.8301\n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 5s 685us/step - loss: 0.3924 - accuracy: 0.8308 - val_loss: 0.3942 - val_accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 6s 778us/step - loss: 0.3921 - accuracy: 0.8310 - val_loss: 0.3938 - val_accuracy: 0.8304\n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 6s 811us/step - loss: 0.3918 - accuracy: 0.8312 - val_loss: 0.3936 - val_accuracy: 0.8305\n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 6s 779us/step - loss: 0.3916 - accuracy: 0.8312 - val_loss: 0.3934 - val_accuracy: 0.8304\n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 6s 827us/step - loss: 0.3913 - accuracy: 0.8314 - val_loss: 0.3930 - val_accuracy: 0.8309\n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 6s 751us/step - loss: 0.3911 - accuracy: 0.8315 - val_loss: 0.3928 - val_accuracy: 0.8310\n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 6s 735us/step - loss: 0.3908 - accuracy: 0.8317 - val_loss: 0.3925 - val_accuracy: 0.8310\n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 5s 668us/step - loss: 0.3906 - accuracy: 0.8319 - val_loss: 0.3923 - val_accuracy: 0.8311\n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 6s 774us/step - loss: 0.3903 - accuracy: 0.8321 - val_loss: 0.3920 - val_accuracy: 0.8312\n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 6s 852us/step - loss: 0.3901 - accuracy: 0.8320 - val_loss: 0.3918 - val_accuracy: 0.8313\n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 5s 658us/step - loss: 0.3898 - accuracy: 0.8325 - val_loss: 0.3916 - val_accuracy: 0.8314\n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 7s 996us/step - loss: 0.3896 - accuracy: 0.8325 - val_loss: 0.3914 - val_accuracy: 0.8315\n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 6s 782us/step - loss: 0.3894 - accuracy: 0.8325 - val_loss: 0.3911 - val_accuracy: 0.8317\n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 5s 708us/step - loss: 0.3892 - accuracy: 0.8327 - val_loss: 0.3909 - val_accuracy: 0.8318\n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 5s 664us/step - loss: 0.3890 - accuracy: 0.8328 - val_loss: 0.3907 - val_accuracy: 0.8320\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 5s 696us/step - loss: 0.3888 - accuracy: 0.8329 - val_loss: 0.3905 - val_accuracy: 0.8321\n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 5s 644us/step - loss: 0.3886 - accuracy: 0.8330 - val_loss: 0.3904 - val_accuracy: 0.8320\n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 5s 633us/step - loss: 0.3884 - accuracy: 0.8330 - val_loss: 0.3902 - val_accuracy: 0.8321\n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 5s 606us/step - loss: 0.3882 - accuracy: 0.8332 - val_loss: 0.3900 - val_accuracy: 0.8323\n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 5s 605us/step - loss: 0.3881 - accuracy: 0.8334 - val_loss: 0.3900 - val_accuracy: 0.8323\n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 5s 635us/step - loss: 0.3879 - accuracy: 0.8333 - val_loss: 0.3897 - val_accuracy: 0.8321\n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 4s 565us/step - loss: 0.3878 - accuracy: 0.8334 - val_loss: 0.3895 - val_accuracy: 0.8322\n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 4s 557us/step - loss: 0.3876 - accuracy: 0.8333 - val_loss: 0.3894 - val_accuracy: 0.8325\n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 4s 580us/step - loss: 0.3875 - accuracy: 0.8335 - val_loss: 0.3892 - val_accuracy: 0.8326\n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 5s 631us/step - loss: 0.3873 - accuracy: 0.8336 - val_loss: 0.3891 - val_accuracy: 0.8327\n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 5s 616us/step - loss: 0.3872 - accuracy: 0.8338 - val_loss: 0.3890 - val_accuracy: 0.8328\n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 4s 587us/step - loss: 0.3871 - accuracy: 0.8337 - val_loss: 0.3890 - val_accuracy: 0.8327\n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 4s 571us/step - loss: 0.3869 - accuracy: 0.8338 - val_loss: 0.3888 - val_accuracy: 0.8329\n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 5s 613us/step - loss: 0.3868 - accuracy: 0.8338 - val_loss: 0.3887 - val_accuracy: 0.8328\n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 4s 552us/step - loss: 0.3867 - accuracy: 0.8339 - val_loss: 0.3886 - val_accuracy: 0.8330\n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 4s 562us/step - loss: 0.3866 - accuracy: 0.8340 - val_loss: 0.3884 - val_accuracy: 0.8329\n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 5s 675us/step - loss: 0.3865 - accuracy: 0.8340 - val_loss: 0.3884 - val_accuracy: 0.8331\n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - 5s 679us/step - loss: 0.3864 - accuracy: 0.8341 - val_loss: 0.3882 - val_accuracy: 0.8330\n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 5s 729us/step - loss: 0.3863 - accuracy: 0.8340 - val_loss: 0.3882 - val_accuracy: 0.8332\n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 5s 713us/step - loss: 0.3862 - accuracy: 0.8341 - val_loss: 0.3881 - val_accuracy: 0.8331\n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 6s 768us/step - loss: 0.3861 - accuracy: 0.8341 - val_loss: 0.3880 - val_accuracy: 0.8331\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 5s 642us/step - loss: 0.3860 - accuracy: 0.8341 - val_loss: 0.3879 - val_accuracy: 0.8331\n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 5s 697us/step - loss: 0.3859 - accuracy: 0.8342 - val_loss: 0.3878 - val_accuracy: 0.8331\n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 5s 635us/step - loss: 0.3858 - accuracy: 0.8341 - val_loss: 0.3879 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 5s 683us/step - loss: 0.3857 - accuracy: 0.8343 - val_loss: 0.3877 - val_accuracy: 0.8334\n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 5s 675us/step - loss: 0.3856 - accuracy: 0.8343 - val_loss: 0.3876 - val_accuracy: 0.8336\n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 5s 620us/step - loss: 0.3856 - accuracy: 0.8344 - val_loss: 0.3875 - val_accuracy: 0.8330\n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 5s 603us/step - loss: 0.3855 - accuracy: 0.8345 - val_loss: 0.3875 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 5s 638us/step - loss: 0.3854 - accuracy: 0.8343 - val_loss: 0.3874 - val_accuracy: 0.8332\n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 5s 600us/step - loss: 0.3853 - accuracy: 0.8345 - val_loss: 0.3874 - val_accuracy: 0.8335\n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 5s 636us/step - loss: 0.3852 - accuracy: 0.8346 - val_loss: 0.3872 - val_accuracy: 0.8334\n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 5s 622us/step - loss: 0.3852 - accuracy: 0.8346 - val_loss: 0.3872 - val_accuracy: 0.8334\n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 5s 602us/step - loss: 0.3851 - accuracy: 0.8346 - val_loss: 0.3871 - val_accuracy: 0.8335\n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 5s 655us/step - loss: 0.3850 - accuracy: 0.8346 - val_loss: 0.3870 - val_accuracy: 0.8336\n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 6s 740us/step - loss: 0.3850 - accuracy: 0.8345 - val_loss: 0.3870 - val_accuracy: 0.8334\n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 5s 679us/step - loss: 0.3849 - accuracy: 0.8347 - val_loss: 0.3869 - val_accuracy: 0.8335\n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 5s 697us/step - loss: 0.3848 - accuracy: 0.8347 - val_loss: 0.3868 - val_accuracy: 0.8336\n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 5s 690us/step - loss: 0.3847 - accuracy: 0.8347 - val_loss: 0.3868 - val_accuracy: 0.8334\n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 5s 673us/step - loss: 0.3847 - accuracy: 0.8349 - val_loss: 0.3867 - val_accuracy: 0.8334\n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 5s 641us/step - loss: 0.3846 - accuracy: 0.8349 - val_loss: 0.3866 - val_accuracy: 0.8335\n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 5s 714us/step - loss: 0.3845 - accuracy: 0.8347 - val_loss: 0.3866 - val_accuracy: 0.8335\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 5s 685us/step - loss: 0.3845 - accuracy: 0.8348 - val_loss: 0.3865 - val_accuracy: 0.8334\n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 4s 598us/step - loss: 0.3844 - accuracy: 0.8348 - val_loss: 0.3865 - val_accuracy: 0.8335\n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 5s 619us/step - loss: 0.3844 - accuracy: 0.8349 - val_loss: 0.3864 - val_accuracy: 0.8335\n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 5s 651us/step - loss: 0.3843 - accuracy: 0.8350 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 5s 647us/step - loss: 0.3842 - accuracy: 0.8351 - val_loss: 0.3863 - val_accuracy: 0.8335\n",
      "Epoch 80/100\n",
      "7500/7500 [==============================] - 5s 622us/step - loss: 0.3842 - accuracy: 0.8350 - val_loss: 0.3863 - val_accuracy: 0.8335\n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 7s 876us/step - loss: 0.3841 - accuracy: 0.8350 - val_loss: 0.3862 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 5s 664us/step - loss: 0.3841 - accuracy: 0.8350 - val_loss: 0.3862 - val_accuracy: 0.8332\n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 5s 677us/step - loss: 0.3840 - accuracy: 0.8349 - val_loss: 0.3861 - val_accuracy: 0.8332\n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 5s 616us/step - loss: 0.3840 - accuracy: 0.8350 - val_loss: 0.3861 - val_accuracy: 0.8334\n",
      "Epoch 85/100\n",
      "7500/7500 [==============================] - 5s 642us/step - loss: 0.3839 - accuracy: 0.8352 - val_loss: 0.3860 - val_accuracy: 0.8335\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 6s 832us/step - loss: 0.3839 - accuracy: 0.8348 - val_loss: 0.3861 - val_accuracy: 0.8335\n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 5s 618us/step - loss: 0.3838 - accuracy: 0.8352 - val_loss: 0.3860 - val_accuracy: 0.8338\n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 5s 618us/step - loss: 0.3838 - accuracy: 0.8350 - val_loss: 0.3859 - val_accuracy: 0.8335\n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 4s 553us/step - loss: 0.3837 - accuracy: 0.8350 - val_loss: 0.3858 - val_accuracy: 0.8335\n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 4s 531us/step - loss: 0.3837 - accuracy: 0.8351 - val_loss: 0.3858 - val_accuracy: 0.8335\n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 4s 531us/step - loss: 0.3836 - accuracy: 0.8351 - val_loss: 0.3857 - val_accuracy: 0.8334\n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 4s 531us/step - loss: 0.3836 - accuracy: 0.8352 - val_loss: 0.3857 - val_accuracy: 0.8335\n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 4s 531us/step - loss: 0.3835 - accuracy: 0.8351 - val_loss: 0.3857 - val_accuracy: 0.8331\n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 4s 529us/step - loss: 0.3835 - accuracy: 0.8352 - val_loss: 0.3856 - val_accuracy: 0.8334\n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 4s 574us/step - loss: 0.3834 - accuracy: 0.8352 - val_loss: 0.3856 - val_accuracy: 0.8336\n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 4s 547us/step - loss: 0.3834 - accuracy: 0.8352 - val_loss: 0.3856 - val_accuracy: 0.8332\n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 4s 532us/step - loss: 0.3834 - accuracy: 0.8354 - val_loss: 0.3855 - val_accuracy: 0.8337\n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 4s 532us/step - loss: 0.3833 - accuracy: 0.8352 - val_loss: 0.3855 - val_accuracy: 0.8334\n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 4s 529us/step - loss: 0.3833 - accuracy: 0.8352 - val_loss: 0.3854 - val_accuracy: 0.8334\n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 4s 535us/step - loss: 0.3832 - accuracy: 0.8354 - val_loss: 0.3854 - val_accuracy: 0.8335\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.834\n",
      "roc-auc is 0.863\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d1077abaf0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to two hidden layers with activation relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (30,),activation = 'relu'))\n",
    "model_1.add(Dense(12,activation='relu'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7500/7500 [==============================] - 5s 601us/step - loss: 0.6763 - accuracy: 0.7950 - val_loss: 0.4338 - val_accuracy: 0.8257\n",
      "Epoch 2/300\n",
      "7500/7500 [==============================] - 4s 588us/step - loss: 2.5695 - accuracy: 0.7714 - val_loss: 2.5942 - val_accuracy: 0.7392\n",
      "Epoch 3/300\n",
      "7500/7500 [==============================] - 4s 575us/step - loss: 1.2651 - accuracy: 0.7479 - val_loss: 0.9644 - val_accuracy: 0.2795\n",
      "Epoch 4/300\n",
      "7500/7500 [==============================] - 4s 595us/step - loss: 2.0081 - accuracy: 0.7423 - val_loss: 4.0681 - val_accuracy: 0.7362\n",
      "Epoch 5/300\n",
      "7500/7500 [==============================] - 5s 613us/step - loss: 2.5602 - accuracy: 0.7350 - val_loss: 0.5755 - val_accuracy: 0.7368\n",
      "Epoch 6/300\n",
      "7500/7500 [==============================] - 4s 556us/step - loss: 0.5701 - accuracy: 0.7401 - val_loss: 0.5651 - val_accuracy: 0.7449\n",
      "Epoch 7/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 0.5635 - accuracy: 0.7451 - val_loss: 0.5600 - val_accuracy: 0.7487\n",
      "Epoch 8/300\n",
      "7500/7500 [==============================] - 4s 565us/step - loss: 0.5594 - accuracy: 0.7482 - val_loss: 0.5566 - val_accuracy: 0.7508\n",
      "Epoch 9/300\n",
      "7500/7500 [==============================] - 4s 559us/step - loss: 0.5576 - accuracy: 0.7512 - val_loss: 0.5567 - val_accuracy: 0.7512\n",
      "Epoch 10/300\n",
      "7500/7500 [==============================] - 4s 558us/step - loss: 0.5508 - accuracy: 0.7640 - val_loss: 0.5636 - val_accuracy: 0.7389\n",
      "Epoch 11/300\n",
      "7500/7500 [==============================] - 4s 561us/step - loss: 2.0560 - accuracy: 0.7505 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 12/300\n",
      "7500/7500 [==============================] - 4s 564us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 13/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 14/300\n",
      "7500/7500 [==============================] - 5s 656us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 15/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 16/300\n",
      "7500/7500 [==============================] - 4s 564us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 17/300\n",
      "7500/7500 [==============================] - 4s 560us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 18/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 19/300\n",
      "7500/7500 [==============================] - 4s 560us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 20/300\n",
      "7500/7500 [==============================] - 4s 569us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 21/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 22/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 23/300\n",
      "7500/7500 [==============================] - 4s 558us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 24/300\n",
      "7500/7500 [==============================] - 4s 559us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 25/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 26/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 27/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 28/300\n",
      "7500/7500 [==============================] - 4s 562us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 29/300\n",
      "7500/7500 [==============================] - 5s 614us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 30/300\n",
      "7500/7500 [==============================] - 5s 676us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 31/300\n",
      "7500/7500 [==============================] - 5s 680us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 32/300\n",
      "7500/7500 [==============================] - 5s 663us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 33/300\n",
      "7500/7500 [==============================] - 5s 618us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 34/300\n",
      "7500/7500 [==============================] - 6s 819us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 35/300\n",
      "7500/7500 [==============================] - 5s 689us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 36/300\n",
      "7500/7500 [==============================] - 5s 646us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 37/300\n",
      "7500/7500 [==============================] - 5s 648us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 38/300\n",
      "7500/7500 [==============================] - 6s 831us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 39/300\n",
      "7500/7500 [==============================] - 5s 709us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 40/300\n",
      "7500/7500 [==============================] - 5s 614us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 41/300\n",
      "7500/7500 [==============================] - 4s 530us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 42/300\n",
      "7500/7500 [==============================] - 4s 530us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 43/300\n",
      "7500/7500 [==============================] - 4s 580us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 44/300\n",
      "7500/7500 [==============================] - 4s 540us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 45/300\n",
      "7500/7500 [==============================] - 4s 532us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 46/300\n",
      "7500/7500 [==============================] - 4s 519us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 47/300\n",
      "7500/7500 [==============================] - 4s 527us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 48/300\n",
      "7500/7500 [==============================] - 4s 565us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 49/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 50/300\n",
      "7500/7500 [==============================] - 4s 549us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 51/300\n",
      "7500/7500 [==============================] - 4s 555us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 52/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 53/300\n",
      "7500/7500 [==============================] - 4s 550us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 54/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 55/300\n",
      "7500/7500 [==============================] - 4s 566us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 56/300\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 57/300\n",
      "7500/7500 [==============================] - 4s 554us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 58/300\n",
      "7500/7500 [==============================] - 4s 577us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 59/300\n",
      "7500/7500 [==============================] - 5s 604us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 60/300\n",
      "7500/7500 [==============================] - 4s 541us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 61/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 62/300\n",
      "7500/7500 [==============================] - 4s 558us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 63/300\n",
      "7500/7500 [==============================] - 4s 556us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 64/300\n",
      "7500/7500 [==============================] - 4s 564us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 65/300\n",
      "7500/7500 [==============================] - 4s 556us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 66/300\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 67/300\n",
      "7500/7500 [==============================] - 5s 624us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 68/300\n",
      "7500/7500 [==============================] - 5s 610us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 69/300\n",
      "7500/7500 [==============================] - 4s 566us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 70/300\n",
      "7500/7500 [==============================] - 5s 603us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 71/300\n",
      "7500/7500 [==============================] - 4s 567us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 72/300\n",
      "7500/7500 [==============================] - 5s 604us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 73/300\n",
      "7500/7500 [==============================] - 5s 630us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 74/300\n",
      "7500/7500 [==============================] - 5s 612us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 75/300\n",
      "7500/7500 [==============================] - 5s 629us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 76/300\n",
      "7500/7500 [==============================] - 5s 673us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 77/300\n",
      "7500/7500 [==============================] - 5s 653us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 78/300\n",
      "7500/7500 [==============================] - 4s 573us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 79/300\n",
      "7500/7500 [==============================] - 4s 590us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 80/300\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 81/300\n",
      "7500/7500 [==============================] - 5s 608us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 82/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 83/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 84/300\n",
      "7500/7500 [==============================] - 5s 609us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 85/300\n",
      "7500/7500 [==============================] - 5s 658us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 86/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 87/300\n",
      "7500/7500 [==============================] - 4s 589us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 88/300\n",
      "7500/7500 [==============================] - 5s 625us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 89/300\n",
      "7500/7500 [==============================] - 5s 682us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 90/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 91/300\n",
      "7500/7500 [==============================] - 4s 575us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 92/300\n",
      "7500/7500 [==============================] - 4s 569us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 93/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 94/300\n",
      "7500/7500 [==============================] - 4s 574us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 95/300\n",
      "7500/7500 [==============================] - 4s 574us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 96/300\n",
      "7500/7500 [==============================] - 4s 550us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 97/300\n",
      "7500/7500 [==============================] - 4s 529us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 98/300\n",
      "7500/7500 [==============================] - 4s 557us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 99/300\n",
      "7500/7500 [==============================] - 4s 541us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 100/300\n",
      "7500/7500 [==============================] - 4s 528us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 101/300\n",
      "7500/7500 [==============================] - 4s 526us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 102/300\n",
      "7500/7500 [==============================] - 4s 537us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 103/300\n",
      "7500/7500 [==============================] - 4s 542us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 104/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 105/300\n",
      "7500/7500 [==============================] - 4s 535us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 106/300\n",
      "7500/7500 [==============================] - 4s 547us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 107/300\n",
      "7500/7500 [==============================] - 4s 558us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 108/300\n",
      "7500/7500 [==============================] - 5s 653us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 109/300\n",
      "7500/7500 [==============================] - 5s 672us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 110/300\n",
      "7500/7500 [==============================] - 5s 613us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 4s 596us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 112/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 113/300\n",
      "7500/7500 [==============================] - 4s 543us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 114/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 115/300\n",
      "7500/7500 [==============================] - 4s 540us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 116/300\n",
      "7500/7500 [==============================] - 4s 541us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 117/300\n",
      "7500/7500 [==============================] - 4s 541us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 118/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 119/300\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 120/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 121/300\n",
      "7500/7500 [==============================] - 4s 540us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 122/300\n",
      "7500/7500 [==============================] - 4s 548us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 123/300\n",
      "7500/7500 [==============================] - 5s 606us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 124/300\n",
      "7500/7500 [==============================] - 4s 553us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 125/300\n",
      "7500/7500 [==============================] - 4s 543us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 126/300\n",
      "7500/7500 [==============================] - 4s 544us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 127/300\n",
      "7500/7500 [==============================] - 4s 542us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 128/300\n",
      "7500/7500 [==============================] - 4s 548us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 129/300\n",
      "7500/7500 [==============================] - 4s 547us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 130/300\n",
      "7500/7500 [==============================] - 4s 543us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 131/300\n",
      "7500/7500 [==============================] - 4s 555us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 132/300\n",
      "7500/7500 [==============================] - 4s 548us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 133/300\n",
      "7500/7500 [==============================] - 5s 613us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 134/300\n",
      "7500/7500 [==============================] - 4s 592us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 135/300\n",
      "7500/7500 [==============================] - 5s 609us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 136/300\n",
      "7500/7500 [==============================] - 4s 566us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 137/300\n",
      "7500/7500 [==============================] - 4s 554us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 138/300\n",
      "7500/7500 [==============================] - 4s 557us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 139/300\n",
      "7500/7500 [==============================] - 4s 571us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 140/300\n",
      "7500/7500 [==============================] - 5s 607us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 141/300\n",
      "7500/7500 [==============================] - 4s 600us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 142/300\n",
      "7500/7500 [==============================] - 4s 571us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 143/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 144/300\n",
      "7500/7500 [==============================] - 4s 574us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 145/300\n",
      "7500/7500 [==============================] - 4s 573us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 146/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 147/300\n",
      "7500/7500 [==============================] - 4s 575us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 148/300\n",
      "7500/7500 [==============================] - 4s 571us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 149/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 150/300\n",
      "7500/7500 [==============================] - 5s 611us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 151/300\n",
      "7500/7500 [==============================] - 5s 648us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 152/300\n",
      "7500/7500 [==============================] - 4s 580us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 153/300\n",
      "7500/7500 [==============================] - 4s 575us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 154/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 155/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 156/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 157/300\n",
      "7500/7500 [==============================] - 4s 577us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 158/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 159/300\n",
      "7500/7500 [==============================] - 5s 601us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 160/300\n",
      "7500/7500 [==============================] - 4s 595us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 161/300\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 162/300\n",
      "7500/7500 [==============================] - 4s 582us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 163/300\n",
      "7500/7500 [==============================] - 4s 588us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 164/300\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 165/300\n",
      "7500/7500 [==============================] - 5s 622us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 4s 585us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 167/300\n",
      "7500/7500 [==============================] - 4s 561us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 168/300\n",
      "7500/7500 [==============================] - 4s 565us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 169/300\n",
      "7500/7500 [==============================] - 4s 562us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 170/300\n",
      "7500/7500 [==============================] - 4s 564us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 171/300\n",
      "7500/7500 [==============================] - 4s 559us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 172/300\n",
      "7500/7500 [==============================] - 4s 562us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 173/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 174/300\n",
      "7500/7500 [==============================] - 4s 569us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 175/300\n",
      "7500/7500 [==============================] - 4s 561us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 176/300\n",
      "7500/7500 [==============================] - 4s 557us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 177/300\n",
      "7500/7500 [==============================] - 4s 595us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 178/300\n",
      "7500/7500 [==============================] - 4s 582us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 179/300\n",
      "7500/7500 [==============================] - 4s 596us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 180/300\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 181/300\n",
      "7500/7500 [==============================] - 5s 605us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 182/300\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 183/300\n",
      "7500/7500 [==============================] - 5s 606us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 184/300\n",
      "7500/7500 [==============================] - 4s 572us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 185/300\n",
      "7500/7500 [==============================] - 4s 552us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 186/300\n",
      "7500/7500 [==============================] - 4s 552us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 187/300\n",
      "7500/7500 [==============================] - 4s 538us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 188/300\n",
      "7500/7500 [==============================] - 5s 629us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 189/300\n",
      "7500/7500 [==============================] - 5s 646us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 190/300\n",
      "7500/7500 [==============================] - 4s 553us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 191/300\n",
      "7500/7500 [==============================] - 4s 560us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 192/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 193/300\n",
      "7500/7500 [==============================] - 5s 650us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 194/300\n",
      "7500/7500 [==============================] - 5s 662us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 195/300\n",
      "7500/7500 [==============================] - 5s 703us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 196/300\n",
      "7500/7500 [==============================] - 5s 703us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 197/300\n",
      "7500/7500 [==============================] - 5s 679us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 198/300\n",
      "7500/7500 [==============================] - 5s 648us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 199/300\n",
      "7500/7500 [==============================] - 5s 603us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 200/300\n",
      "7500/7500 [==============================] - 4s 599us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 201/300\n",
      "7500/7500 [==============================] - 5s 702us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 202/300\n",
      "7500/7500 [==============================] - 5s 716us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 203/300\n",
      "7500/7500 [==============================] - 5s 714us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 204/300\n",
      "7500/7500 [==============================] - 6s 847us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 205/300\n",
      "7500/7500 [==============================] - 5s 626us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 206/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 207/300\n",
      "7500/7500 [==============================] - 5s 612us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 208/300\n",
      "7500/7500 [==============================] - 5s 635us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 209/300\n",
      "7500/7500 [==============================] - 5s 707us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 210/300\n",
      "7500/7500 [==============================] - 5s 656us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 211/300\n",
      "7500/7500 [==============================] - 5s 692us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 212/300\n",
      "7500/7500 [==============================] - 5s 687us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 213/300\n",
      "7500/7500 [==============================] - 5s 616us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 214/300\n",
      "7500/7500 [==============================] - 4s 571us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 215/300\n",
      "7500/7500 [==============================] - 4s 573us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 216/300\n",
      "7500/7500 [==============================] - 4s 564us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 217/300\n",
      "7500/7500 [==============================] - 5s 601us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 218/300\n",
      "7500/7500 [==============================] - 4s 551us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 219/300\n",
      "7500/7500 [==============================] - 4s 543us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 220/300\n",
      "7500/7500 [==============================] - 5s 604us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 5s 699us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 222/300\n",
      "7500/7500 [==============================] - 5s 653us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 223/300\n",
      "7500/7500 [==============================] - 5s 699us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 224/300\n",
      "7500/7500 [==============================] - 4s 552us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 225/300\n",
      "7500/7500 [==============================] - 4s 528us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 226/300\n",
      "7500/7500 [==============================] - 4s 531us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 227/300\n",
      "7500/7500 [==============================] - 4s 530us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 228/300\n",
      "7500/7500 [==============================] - 4s 534us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 229/300\n",
      "7500/7500 [==============================] - 4s 522us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 230/300\n",
      "7500/7500 [==============================] - 5s 601us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 231/300\n",
      "7500/7500 [==============================] - 5s 628us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 232/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 233/300\n",
      "7500/7500 [==============================] - 4s 593us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 234/300\n",
      "7500/7500 [==============================] - 4s 586us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 235/300\n",
      "7500/7500 [==============================] - 6s 750us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 236/300\n",
      "7500/7500 [==============================] - 5s 654us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 237/300\n",
      "7500/7500 [==============================] - 7s 935us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 238/300\n",
      "7500/7500 [==============================] - 5s 714us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 239/300\n",
      "7500/7500 [==============================] - 5s 711us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 240/300\n",
      "7500/7500 [==============================] - 5s 716us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 241/300\n",
      "7500/7500 [==============================] - 5s 656us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 242/300\n",
      "7500/7500 [==============================] - 4s 592us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 243/300\n",
      "7500/7500 [==============================] - 5s 614us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 244/300\n",
      "7500/7500 [==============================] - 5s 669us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 245/300\n",
      "7500/7500 [==============================] - 4s 530us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 246/300\n",
      "7500/7500 [==============================] - 4s 528us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 247/300\n",
      "7500/7500 [==============================] - 4s 524us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 248/300\n",
      "7500/7500 [==============================] - 4s 599us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 249/300\n",
      "7500/7500 [==============================] - 4s 529us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 250/300\n",
      "7500/7500 [==============================] - 4s 528us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 251/300\n",
      "7500/7500 [==============================] - 4s 539us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 252/300\n",
      "7500/7500 [==============================] - 5s 663us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 253/300\n",
      "7500/7500 [==============================] - 5s 726us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 254/300\n",
      "7500/7500 [==============================] - 5s 618us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 255/300\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 256/300\n",
      "7500/7500 [==============================] - 5s 634us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 257/300\n",
      "7500/7500 [==============================] - 4s 584us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 258/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 259/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 260/300\n",
      "7500/7500 [==============================] - 4s 576us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 261/300\n",
      "7500/7500 [==============================] - 4s 581us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 262/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 263/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 264/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 265/300\n",
      "7500/7500 [==============================] - 4s 574us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 266/300\n",
      "7500/7500 [==============================] - 5s 619us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 267/300\n",
      "7500/7500 [==============================] - 10s 1ms/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 268/300\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 269/300\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 270/300\n",
      "7500/7500 [==============================] - 5s 631us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 271/300\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 272/300\n",
      "7500/7500 [==============================] - 4s 585us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 273/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 274/300\n",
      "7500/7500 [==============================] - 4s 585us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 275/300\n",
      "7500/7500 [==============================] - 4s 582us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 276/300\n",
      "7500/7500 [==============================] - 4s 585us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 277/300\n",
      "7500/7500 [==============================] - 4s 577us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 278/300\n",
      "7500/7500 [==============================] - 4s 596us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 279/300\n",
      "7500/7500 [==============================] - 4s 573us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 280/300\n",
      "7500/7500 [==============================] - 4s 549us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 281/300\n",
      "7500/7500 [==============================] - 4s 550us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 282/300\n",
      "7500/7500 [==============================] - 4s 552us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 283/300\n",
      "7500/7500 [==============================] - 4s 550us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 284/300\n",
      "7500/7500 [==============================] - 4s 562us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 285/300\n",
      "7500/7500 [==============================] - 4s 575us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 286/300\n",
      "7500/7500 [==============================] - 4s 541us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 287/300\n",
      "7500/7500 [==============================] - 5s 619us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 288/300\n",
      "7500/7500 [==============================] - 4s 579us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 289/300\n",
      "7500/7500 [==============================] - 4s 573us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 290/300\n",
      "7500/7500 [==============================] - 5s 615us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 291/300\n",
      "7500/7500 [==============================] - 4s 582us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 292/300\n",
      "7500/7500 [==============================] - 5s 615us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 293/300\n",
      "7500/7500 [==============================] - 4s 587us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 294/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 295/300\n",
      "7500/7500 [==============================] - 4s 544us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 296/300\n",
      "7500/7500 [==============================] - 4s 545us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 297/300\n",
      "7500/7500 [==============================] - 4s 559us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 298/300\n",
      "7500/7500 [==============================] - 4s 595us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 299/300\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n",
      "Epoch 300/300\n",
      "7500/7500 [==============================] - 4s 582us/step - loss: 4.0899 - accuracy: 0.7348 - val_loss: 4.0683 - val_accuracy: 0.7362\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.736\n",
      "roc-auc is 0.500\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21141cccd00>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X)\n",
    "y_pred_prob_nn_1 = model_1.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.165381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  0.094652\n",
       "1  0.503521\n",
       "2  0.165381\n",
       "3  0.087442\n",
       "4  0.148275"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.DataFrame({'target': y_pred_prob_nn_1[:,0]})\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.094652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.503521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.165381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.148275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   5  0.094652\n",
       "1   6  0.503521\n",
       "2   8  0.165381\n",
       "3   9  0.087442\n",
       "4  11  0.148275"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final1 = pd.concat([df1['id'],final],axis=1)\n",
    "final1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
